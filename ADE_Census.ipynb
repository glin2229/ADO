{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9APaGOB2XGM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "outputId": "dda566bc-4f05-484c-e3cb-aefc8c8967d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.44.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (71.0.4)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-75.1.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading setuptools-75.1.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pip-24.2-py3-none-any.whl (1.8 MB)\n",
            "Installing collected packages: setuptools, pip\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 71.0.4\n",
            "    Uninstalling setuptools-71.0.4:\n",
            "      Successfully uninstalled setuptools-71.0.4\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pip-24.2 setuptools-75.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources",
                  "setuptools"
                ]
              },
              "id": "7cb11736d59c4aaeb017e8d2712740b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.45.1-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.3)\n",
            "Downloading openai-1.45.1-py3-none-any.whl (374 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "Installing collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 openai-1.45.1\n"
          ]
        }
      ],
      "source": [
        "!pip install wheel setuptools pip --upgrade\n",
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from openai import OpenAI\n",
        "import time\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "census_df = pd.read_csv('census_small.csv', header = None)\n",
        "\n",
        "# Define the column names\n",
        "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n",
        "                'occupation', 'relationship', 'race', 'sex', 'capital-gain',\n",
        "                'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
        "\n",
        "# Assign the column names to the DataFrame\n",
        "census_df.columns = column_names\n",
        "census_df.fillna('Unknown')\n",
        "\n",
        "print( census_df['income'].unique() )\n",
        "census_df['income'] = census_df['income'].replace(' <=50K', 'not exceeding')\n",
        "census_df['income'] = census_df['income'].replace(' >50K', 'exceeding')\n",
        "census_df.drop(columns=['fnlwgt', 'education-num'], inplace=True)\n",
        "print( census_df['income'].unique() )\n",
        "\n",
        "# # Apply qcut to each numerical column to divide into 20 bins\n",
        "# for column in census_df.select_dtypes(include=[np.number]).columns:\n",
        "#     census_df[column], bins = pd.cut(census_df[column], 30, duplicates='drop', retbins=True)\n",
        "\n",
        "# create a tuning set\n",
        "tuning_set = census_df.sample(n=800, random_state=0)\n",
        "percentage_yes = (tuning_set['income'] == 'exceeding').mean()\n",
        "print(percentage_yes)\n",
        "\n",
        "row_series = tuning_set.iloc[0][:-1]\n",
        "target = tuning_set.iloc[0]['income']\n",
        "\n",
        "all_features = ''\n",
        "for feature, value in row_series.items():\n",
        "    all_features += feature + ', '\n",
        "\n",
        "print(all_features)\n",
        "\n",
        "\n",
        "selected_rows_1 = census_df.loc[census_df['income'] == 'exceeding'].head(5)\n",
        "\n",
        "selected_rows_2 = census_df.loc[census_df['income'] == 'not exceeding'].head(4)\n",
        "\n",
        "# Combine the two DataFrames into a new DataFrame\n",
        "combined_df = pd.concat([selected_rows_1, selected_rows_2], ignore_index=True)\n",
        "\n",
        "samples = []\n",
        "targets = []\n",
        "for i in range( len(combined_df) ):\n",
        "    row_series = combined_df.iloc[i][:-1]\n",
        "    target = combined_df.iloc[i]['income']\n",
        "\n",
        "    overall_feature_levels = ''\n",
        "    for feature, value in row_series.items():\n",
        "        feature_level = (f\"Feature: {feature}, Value: {value}\")\n",
        "        overall_feature_levels += feature_level + '; '\n",
        "\n",
        "    samples.append(overall_feature_levels)\n",
        "    targets.append(target)\n",
        "\n",
        "print(samples)\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWSj98WV5Afz",
        "outputId": "da83e818-789c-49e2-df63-097ccca56bb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' <=50K' ' >50K']\n",
            "['not exceeding' 'exceeding']\n",
            "0.265\n",
            "age, workclass, education, marital-status, occupation, relationship, race, sex, capital-gain, capital-loss, hours-per-week, native-country, \n",
            "['Feature: age, Value: 52; Feature: workclass, Value:  Self-emp-not-inc; Feature: education, Value:  HS-grad; Feature: marital-status, Value:  Married-civ-spouse; Feature: occupation, Value:  Exec-managerial; Feature: relationship, Value:  Husband; Feature: race, Value:  White; Feature: sex, Value:  Male; Feature: capital-gain, Value: 0; Feature: capital-loss, Value: 0; Feature: hours-per-week, Value: 45; Feature: native-country, Value:  United-States; ', 'Feature: age, Value: 31; Feature: workclass, Value:  Private; Feature: education, Value:  Masters; Feature: marital-status, Value:  Never-married; Feature: occupation, Value:  Prof-specialty; Feature: relationship, Value:  Not-in-family; Feature: race, Value:  White; Feature: sex, Value:  Female; Feature: capital-gain, Value: 14084; Feature: capital-loss, Value: 0; Feature: hours-per-week, Value: 50; Feature: native-country, Value:  United-States; ', 'Feature: age, Value: 42; Feature: workclass, Value:  Private; Feature: education, Value:  Bachelors; Feature: marital-status, Value:  Married-civ-spouse; Feature: occupation, Value:  Exec-managerial; Feature: relationship, Value:  Husband; Feature: race, Value:  White; Feature: sex, Value:  Male; Feature: capital-gain, Value: 5178; Feature: capital-loss, Value: 0; Feature: hours-per-week, Value: 40; Feature: native-country, Value:  United-States; ', 'Feature: age, Value: 37; Feature: workclass, Value:  Private; Feature: education, Value:  Some-college; Feature: marital-status, Value:  Married-civ-spouse; Feature: occupation, Value:  Exec-managerial; Feature: relationship, Value:  Husband; Feature: race, Value:  Black; Feature: sex, Value:  Male; Feature: capital-gain, Value: 0; Feature: capital-loss, Value: 0; Feature: hours-per-week, Value: 80; Feature: native-country, Value:  United-States; ', 'Feature: age, Value: 30; Feature: workclass, Value:  State-gov; Feature: education, Value:  Bachelors; Feature: marital-status, Value:  Married-civ-spouse; Feature: occupation, Value:  Prof-specialty; Feature: relationship, Value:  Husband; Feature: race, Value:  Asian-Pac-Islander; Feature: sex, Value:  Male; Feature: capital-gain, Value: 0; Feature: capital-loss, Value: 0; Feature: hours-per-week, Value: 40; Feature: native-country, Value:  India; ', 'Feature: age, Value: 39; Feature: workclass, Value:  State-gov; Feature: education, Value:  Bachelors; Feature: marital-status, Value:  Never-married; Feature: occupation, Value:  Adm-clerical; Feature: relationship, Value:  Not-in-family; Feature: race, Value:  White; Feature: sex, Value:  Male; Feature: capital-gain, Value: 2174; Feature: capital-loss, Value: 0; Feature: hours-per-week, Value: 40; Feature: native-country, Value:  United-States; ', 'Feature: age, Value: 50; Feature: workclass, Value:  Self-emp-not-inc; Feature: education, Value:  Bachelors; Feature: marital-status, Value:  Married-civ-spouse; Feature: occupation, Value:  Exec-managerial; Feature: relationship, Value:  Husband; Feature: race, Value:  White; Feature: sex, Value:  Male; Feature: capital-gain, Value: 0; Feature: capital-loss, Value: 0; Feature: hours-per-week, Value: 13; Feature: native-country, Value:  United-States; ', 'Feature: age, Value: 38; Feature: workclass, Value:  Private; Feature: education, Value:  HS-grad; Feature: marital-status, Value:  Divorced; Feature: occupation, Value:  Handlers-cleaners; Feature: relationship, Value:  Not-in-family; Feature: race, Value:  White; Feature: sex, Value:  Male; Feature: capital-gain, Value: 0; Feature: capital-loss, Value: 0; Feature: hours-per-week, Value: 40; Feature: native-country, Value:  United-States; ', 'Feature: age, Value: 53; Feature: workclass, Value:  Private; Feature: education, Value:  11th; Feature: marital-status, Value:  Married-civ-spouse; Feature: occupation, Value:  Handlers-cleaners; Feature: relationship, Value:  Husband; Feature: race, Value:  Black; Feature: sex, Value:  Male; Feature: capital-gain, Value: 0; Feature: capital-loss, Value: 0; Feature: hours-per-week, Value: 40; Feature: native-country, Value:  United-States; ']\n",
            "['exceeding', 'exceeding', 'exceeding', 'exceeding', 'exceeding', 'not exceeding', 'not exceeding', 'not exceeding', 'not exceeding']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3PgpOPQ9IIrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY = ''\n",
        "client = OpenAI(api_key = API_KEY)\n",
        "model_id = 'gpt-3.5-turbo-0125'\n",
        "\n",
        "APE_prompt = f\"\"\"\n",
        "You are given a set of feature-value pairs that represents a person's profile. Your task is to propose a creative, detailed, and step-by-step algorithm to reformulate and enrich this profile. The goal is of the algorithm is to perform a thorough data engineering among the features, so that it is easier for a LLM to distinguish whether the person has a annual income that exceeds $50,000, specifically in the year of 1995. Below are some sample profiles as refrences.\n",
        "\n",
        "Examples:\n",
        "- Job Description: '{samples[0]}'; Is the job Fraud or not: '{targets[0]}'\n",
        "- Job Description: '{samples[1]}'; Is the job Fraud or not: '{targets[1]}'\n",
        "- Job Description: '{samples[2]}'; Is the job Fraud or not: '{targets[2]}'\n",
        "- Job Description: '{samples[6]}'; Is the job Fraud or not: '{targets[6]}'\n",
        "- Job Description: '{samples[7]}'; Is the job Fraud or not: '{targets[7]}'\n",
        "- Job Description: '{samples[8]}'; Is the job Fraud or not: '{targets[8]}'\n",
        "\n",
        "For each step of the algorithm, number and then start it on a new line; you must start each step with '###------- Step 1: ' The proposed algorithm will later be submitted to a LLM for processing.\n",
        "Important: Do NOT refer to any external database; Do NOT perform the item counting. Do NOT perform normalization. Do NOT perform vector generations. Do NOT perform similarity checking. Do NOT propose how to train or generate a recommendation system. ONLY propose things that a LLM can do on its own!\n",
        "\"\"\"\n",
        "\n",
        "prompts = []\n",
        "prompt_performances = {}\n",
        "for i in range(7):\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model = model_id, temperature = 1.0,\n",
        "\n",
        "        messages=[{\"role\": \"system\", \"content\": \"Please come up with a step-by-step, very detailed, clear, and novel algorithm for reformulating and enriching a person's profile. Return the steps ONLY!!! NO more than 5 steps. You MUST NOT directly include whether the person has a annual income that exceeds $50,000!!!\"},\n",
        "                    {\"role\": \"user\", \"content\": APE_prompt}],\n",
        "        timeout = 1200)\n",
        "\n",
        "    candidate_prompt = completion.choices[0].message.content\n",
        "    prompts.append(candidate_prompt)\n",
        "    print(candidate_prompt)\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "PhImhnjZIIyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Regular expression to split the text into individual algorithms\n",
        "algorithm_pattern = r\"###------- Step \\d: [\\w\\s]+\"\n",
        "\n",
        "# Split the text based on the pattern\n",
        "split_text = re.split(algorithm_pattern, candidate_prompt)\n",
        "\n",
        "# Extract the algorithm headers (for identification)\n",
        "headers = re.findall(algorithm_pattern, candidate_prompt)\n",
        "\n",
        "# Removing the first empty string from the split if exists (because of the split at the start)\n",
        "split_text = [t.strip() for t in split_text if t.strip()]\n",
        "\n",
        "# Create a dictionary where each algorithm is stored separately\n",
        "algorithms = {headers[i]: split_text[i] for i in range(len(headers))}\n",
        "\n",
        "# Display each algorithm separately\n",
        "steps = []\n",
        "for header, content in algorithms.items():\n",
        "    steps.append( [header, content] )\n",
        "    print(f\"{header}:\\n{content}\\n\")\n"
      ],
      "metadata": {
        "id": "8NY0d91TII3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_msg = \"Please serve as a binary classifier on user income level.\"\n",
        "\n",
        "prompts = []\n",
        "prompts.append(\"\"\"###------- Step 1: Identify key feature-value pairs such as age, education, occupation, workclass, and marital status that may correlate with an annual income exceeding $50,000 in the year 1995.\n",
        "###------- Step 2: Convert categorical variables into numerical representations, for example, mapping education levels to numerical values or encoding occupation types.\n",
        "###------- Step 3: Calculate derived features such as the total capital (capital-gain minus capital-loss) and years of education based on the provided education level.\n",
        "###------- Step 4: Analyze the relationship between hours-per-week and income level to identify any potential trends or thresholds that may indicate high-income levels.\n",
        "###------- Step 5: Iterate through the enriched profile data to identify patterns or combinations of features that are common among individuals with an annual income exceeding $50,000 in 1995.\n",
        "\"\"\")\n",
        "\n",
        "for candidate_prompt in prompts:\n",
        "    print(candidate_prompt)\n",
        "    print()\n",
        "\n",
        "    # Regular expression to split the text into individual algorithms\n",
        "    algorithm_pattern = r\"###------- Step \\d: [\\w\\s]+\"\n",
        "\n",
        "    # Split the text based on the pattern\n",
        "    split_text = re.split(algorithm_pattern, candidate_prompt)\n",
        "\n",
        "    # Extract the algorithm headers (for identification)\n",
        "    headers = re.findall(algorithm_pattern, candidate_prompt)\n",
        "\n",
        "    # Removing the first empty string from the split if exists (because of the split at the start)\n",
        "    split_text = [t.strip() for t in split_text if t.strip()]\n",
        "\n",
        "    # Create a dictionary where each algorithm is stored separately\n",
        "    algorithms = {headers[i]: split_text[i] for i in range(len(headers))}\n",
        "\n",
        "    # Display each algorithm separately\n",
        "    steps = []\n",
        "    for header, content in algorithms.items():\n",
        "        steps.append( [header, content] )\n",
        "        print(f\"{header}:\\n{content}\\n\")\n",
        "\n",
        "\n",
        "    right_count_pos = 0\n",
        "    right_count_neg = 0\n",
        "    compressed_right_count_pos = 0\n",
        "    compressed_right_count_neg = 0\n",
        "    total_pos = 0\n",
        "    total_neg = 0\n",
        "    total = 0\n",
        "\n",
        "    # you may also set range smaller for a subset\n",
        "    for i in range( len(tuning_set) ):\n",
        "        row_series = tuning_set.iloc[i][:-1]\n",
        "        target = tuning_set.iloc[i]['income']\n",
        "\n",
        "        overall_feature_levels = ''\n",
        "        for feature, value in row_series.items():\n",
        "            feature_level = (f\"Feature: {feature}, Value: {value}\")\n",
        "            overall_feature_levels += feature_level + '; '\n",
        "\n",
        "\n",
        "        original_prompt = (\n",
        "            \"You are given an user description with each feature-value pair presented.\"\n",
        "            \"Please determine whether the user had an income higher than $50k in the year of 1993. First write a step-by-step reasoning paragraph, and then output 'exceeding' or 'not exceeding' strictly, in lower case:\"\n",
        "            \"Below is the user description: \\n\\n\"\n",
        "            f\"{overall_feature_levels}\"\n",
        "        )\n",
        "\n",
        "        # original_prompt = (\n",
        "        #     f\"Given the following user description: \\n\\n {overall_feature_levels};\\n\\n\"\n",
        "        #     f\"Please determine whether the user had an income higher than $50k in the year of 1993. Do NOT explain anything, just output 'exceeding' or 'not exceeding', in lower case:\"\n",
        "        # )\n",
        "\n",
        "        completion = client.chat.completions.create(\n",
        "                model = model_id, temperature = 0, seed = 0,\n",
        "                messages=[{\"role\": \"system\", \"content\": system_msg},\n",
        "                            {\"role\": \"user\", \"content\": original_prompt }],\n",
        "                timeout = 1200)\n",
        "\n",
        "        original_pred = completion.choices[0].message.content\n",
        "        # print(original_pred)\n",
        "        # print()\n",
        "\n",
        "        total += 1\n",
        "        if target == 'exceeding':\n",
        "            total_pos += 1\n",
        "        else:\n",
        "            total_neg += 1\n",
        "\n",
        "        if target in original_pred:\n",
        "            if (target == 'exceeding'):\n",
        "                right_count_pos += 1\n",
        "            if (target == 'not exceeding'):\n",
        "                right_count_neg += 1\n",
        "\n",
        "\n",
        "\n",
        "        overall_with_steps = \"Original person's profile: \" + overall_feature_levels + '\\n\\n'\n",
        "        for i in range(len(algorithms)):\n",
        "\n",
        "            reformulation_prompt = f\"Please thoroughly reformulate the person's profile based on the following instruction:\\n\\n{steps[i][0]}\\n{steps[i][1]}\\n\\nprofile to reformulate: {overall_with_steps}\\n\\nYou MUST return the reformulation of the profile ONLY!!!\"\n",
        "\n",
        "            completion = client.chat.completions.create(\n",
        "                    model = model_id, temperature = 0.0, max_tokens = 512,\n",
        "\n",
        "                    messages=[{\"role\": \"system\", \"content\": \"Please reformulate the person's profile to be extremely informative and detailed for LLM to interpret better. You are allowed to fill in unspecified information based on your domain expertise!\"},\n",
        "                                {\"role\": \"user\", \"content\": reformulation_prompt}],\n",
        "                    timeout = 1200)\n",
        "\n",
        "            reformulated_history = completion.choices[0].message.content\n",
        "            # print('Step ' + str(i) + ' Results: ')\n",
        "            # print(reformulated_history)\n",
        "            overall_with_steps += steps[i][0] + '\\n' + steps[i][1] + reformulated_history + '\\n\\n'\n",
        "            # print()\n",
        "            # print()\n",
        "\n",
        "        print(overall_with_steps)\n",
        "        print()\n",
        "\n",
        "\n",
        "        census_prompt = (\n",
        "            \"You are given an user description with each feature-value pair presented.\"\n",
        "            \"Please determine whether the user had an income higher than $50k in the year of 1993. First write a step-by-step reasoning paragraph, and then output 'exceeding' or 'not exceeding' strictly, in lower case:\"\n",
        "            \"Below is the user description: \\n\\n\"\n",
        "            f\"{overall_with_steps}\"\n",
        "        )\n",
        "\n",
        "        # census_prompt = (\n",
        "        #     f\"Given the following user description: \\n\\n {overall_with_steps};\\n\\n\"\n",
        "        #     f\"Please determine whether the user had an income higher than $50k in the year of 1993. Do NOT explain anything, just output 'exceeding' or 'not exceeding', in lower case:\"\n",
        "        # )\n",
        "\n",
        "        compressed_completion = client.chat.completions.create(\n",
        "                model = model_id, temperature = 0, seed = 0,\n",
        "                messages=[{\"role\": \"system\", \"content\": system_msg},\n",
        "                            {\"role\": \"user\", \"content\": census_prompt}],\n",
        "                timeout = 1200)\n",
        "\n",
        "        compressed_pred = compressed_completion.choices[0].message.content\n",
        "        # end\n",
        "\n",
        "\n",
        "        if target in compressed_pred:\n",
        "            if (target == 'exceeding'):\n",
        "                compressed_right_count_pos += 1\n",
        "            if (target == 'not exceeding'):\n",
        "                compressed_right_count_neg += 1\n",
        "\n",
        "\n",
        "        # print(converted_feature_levels)\n",
        "        print(right_count_pos, right_count_neg)\n",
        "        print(compressed_right_count_pos, compressed_right_count_neg)\n",
        "        print()\n",
        "\n",
        "        if total % 100 == 0 or total == census_df.shape[0]:\n",
        "            accuracy = (right_count_pos/total_pos) * 0.5 + (right_count_neg/total_neg) * 0.5\n",
        "            compressed_accuracy = (compressed_right_count_pos/total_pos) * 0.5 + (compressed_right_count_neg/total_neg) * 0.5\n",
        "            print('Accuracy: ', accuracy)\n",
        "            print('Compressed Accuracy: ', compressed_accuracy)\n",
        "            print()\n",
        "\n",
        "            if compressed_accuracy <= accuracy:\n",
        "                break\n",
        "\n",
        "    prompt_performances[candidate_prompt] = [ (right_count_pos/total_pos) * 0.5 + (right_count_neg/total_neg) * 0.5, (compressed_right_count_pos/total_pos) * 0.5 + (compressed_right_count_neg/total_neg) * 0.5 ]\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "zFci7scMII7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = (right_count_pos/total_pos) * 0.5 + (right_count_neg/total_neg) * 0.5\n",
        "compressed_accuracy = (compressed_right_count_pos/total_pos) * 0.5 + (compressed_right_count_neg/total_neg) * 0.5\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Compressed Accuracy: ', compressed_accuracy)\n"
      ],
      "metadata": {
        "id": "siECpO8JIJAz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}